{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gPIyw7-a9iw"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U bitsandbytes"
      ],
      "metadata": {
        "id": "PFp_mkGsnDfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "try:\n",
        "    hf_token = userdata.get('hf_token')\n",
        "    if not hf_token:\n",
        "        print(\"Warning: HF_TOKEN not found in Colab Secrets under 'hf_token'. Proceeding for public model access.\")\n",
        "        hf_token = None\n",
        "except Exception as e:\n",
        "    print(f\"Error retrieving HF_TOKEN: {str(e)}\")\n",
        "    print(\"Warning: Token retrieval failed, but proceeding for public model access.\")\n",
        "    hf_token = None\n",
        "\n",
        "\n",
        "!pip install -U transformers accelerate -q\n",
        "\n",
        "\n",
        "\n",
        "hf_token = os.getenv(\"HF_TOKEN\", None)\n",
        "\n",
        "\n",
        "def generate_questions(intern_profile, job_description):\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert interview question generator for intern roles. Based on the provided intern profile and job description, generate 5 technical and 5 behavioral interview questions tailored to the candidate's skills and the role's requirements. Ensure technical questions match the candidate’s experience level and the job’s technical needs, and behavioral questions follow the STAR framework (Situation, Task, Action, Result).\n",
        "\n",
        "    Intern Profile:\n",
        "    {intern_profile}\n",
        "\n",
        "    Job Description:\n",
        "    {job_description}\n",
        "\n",
        "    Output Format:\n",
        "    Technical Questions:\n",
        "    1. [Question]\n",
        "    2. [Question]\n",
        "    3. [Question]\n",
        "    4. [Question]\n",
        "    5. [Question]\n",
        "\n",
        "    Behavioral Questions:\n",
        "    1. [Question]\n",
        "    2. [Question]\n",
        "    3. [Question]\n",
        "    4. [Question]\n",
        "    5. [Question]\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "    try:\n",
        "\n",
        "        inputs = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            add_generation_prompt=True,\n",
        "            tokenize=True,\n",
        "            return_dict=True,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(model.device)\n",
        "\n",
        "\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=600,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            top_p=0.9\n",
        "        )\n",
        "\n",
        "        generated_text = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
        "        return generated_text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error generating questions: {str(e)}\"\n",
        "\n",
        "\n",
        "intern_profile_1 = \"\"\"\n",
        "- Role: Data Science Intern\n",
        "- Skills: Python, SQL, basic machine learning\n",
        "- Experience: Beginner, 2nd-year BSc Computer Science\n",
        "- Projects: Built a linear regression model for a university project\n",
        "\"\"\"\n",
        "job_description_1 = \"\"\"\n",
        "- Role: Data Science Intern\n",
        "- Skills Required: Python, data analysis, team collaboration\n",
        "- Responsibilities: Analyze datasets, build predictive models, present findings\n",
        "\"\"\"\n",
        "\n",
        "# Sample Input 2: Software Engineering Intern\n",
        "intern_profile_2 = \"\"\"\n",
        "- Role: Software Engineering Intern\n",
        "- Skills: Python, Java, basic understanding of web development (HTML, CSS)\n",
        "- Experience: Beginner, 3rd-year BSc Computer Science\n",
        "- Projects: Developed a simple web application using Flask and Python for a course project\n",
        "\"\"\"\n",
        "job_description_2 = \"\"\"\n",
        "- Role: Software Engineering Intern\n",
        "- Skills Required: Python, Java, web development, problem-solving\n",
        "- Responsibilities: Assist in developing backend features, write clean code, participate in code reviews\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "intern_profile_3 = \"\"\"\n",
        "- Role: Product Management Intern\n",
        "- Skills: Basic Python, user research, communication\n",
        "- Experience: Beginner, 2nd-year BA Business Administration\n",
        "- Projects: Conducted user interviews for a mobile app prototype in a class project\n",
        "\"\"\"\n",
        "job_description_3 = \"\"\"\n",
        "- Role: Product Management Intern\n",
        "- Skills Required: User research, data analysis, teamwork\n",
        "- Responsibilities: Gather user feedback, assist in defining product requirements, analyze usage data\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "sample_inputs = [\n",
        "    (\"Data Science Intern\", intern_profile_1, job_description_1),\n",
        "    (\"Software Engineering Intern\", intern_profile_2, job_description_2),\n",
        "    (\"Product Management Intern\", intern_profile_3, job_description_3)\n",
        "]\n",
        "\n",
        "for role, intern_profile, job_description in sample_inputs:\n",
        "    print(f\"\\n=== {role} Questions ===\")\n",
        "    questions = generate_questions(intern_profile, job_description)\n",
        "    print(questions)"
      ],
      "metadata": {
        "id": "l0dIt8q8buwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_MkN5rYtlmeQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}